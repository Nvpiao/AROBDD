
	
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<meta http-equiv="X-UA-Compatible" content="IE=7" />
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="author" content="Turnitin, LLC" />
    <meta name="keywords" content="" /> 
    <meta name="description" content="" />
    <meta name="viewport" content="width = initial-scale" />
    <meta name="viewport" content="height = initial-scale" />
    
<title>TurnitinUK Originality Report</title>

<base href="http://turnitinuk.com">
<style type="text/css">
	
body	{
	color: #000;
	background: #ddd;
	padding: 0;
	border: 0;
	font: 14px Arial, Verdana, sans-serif;
	margin: 0;
	text-align: center;
	}
	
form	{
	padding: 0;
	margin: 0;
	}
	
p	{
	padding: .8em 1.5em;
	margin: 0;
	text-align: left;
	}
	
img	{
	border: 0;
	padding: 0;
	}

div	{
	padding: 0;
	border: 0;
	text-align: left;
	}
	
strong	{
	font-weight: bold;
	}
	
h2	{
	font-size: 15px;
	margin: 20px 0 10px 20px;
	}
	
a:link, a:visited	{
	text-decoration: underline;
	color: #00f;
	}
	
a:hover, a:active	{
	text-decoration: underline;
	color: #888;
	}
	
img#logo	{
	float: right;
	padding-right: 20px;
	padding-top: 10px;
	}
	
div#container	{
	border: 1px solid #aaa;
	width: 770px;
	margin: 20px auto;
	background: #fff;
	padding: 10px 0;
	}
	
div#top	{
	background: #fff;
	width: 7in;
	margin: auto;
	padding-bottom: 15px;
	}
	
div#content	{
	background: #fff;
	}
	
#top p	{
	padding: .3em 0 .3em 20px;
	}

#top span	{
	padding-right: 35px;
	}
	
#top p#orig	{
	padding-top: 15px;
	}
	
#orig span#score.red	{
	border-right: 18px solid red;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.orange	{
	border-right: 18px solid orange;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.yellow	{
	border-right: 18px solid yellow;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.green	{
	border-right: 18px solid green;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
#orig span#score.blue	{
	border-right: 18px solid blue;
	padding: .2em .5em;
	margin: 0 1em;
	background: white;
	border-top: 1px solid #888;
	border-bottom: 1px solid #888;
	border-left: 1px solid #888;
	}
	
div.divider	{
	width: 7in;
	border: 1px dotted #888;
	margin: auto;
	padding: 4px 0 4px 10px;
	font-weight: bold;
	background: #ddd;
	font-size: 15px;
	}
	
div.links	{
	width: 7in;
	margin: auto;
	}
	
.links div	{
	padding: 15px 20px 15px 20px;
	border-bottom: 1px dotted #888;
	}
	
.links div#last	{
	padding: 15px 20px 20px 20px;
	border-bottom: 0;
	}
	
div.number	{
	float: right;
	background: white;
	border: 1px solid #888;
	margin: 0 0 0 20px;
	padding: .1em .5em;
	text-align: center;
	color: black;
	font-weight: bold;
	font-size: 15px;
	line-height: 20px;
	}
	
div.number-l	{
	float: left;
	background: white;
	border: 1px solid #888;
	margin: 6px 16px 10px 0;
	padding: .1em .5em;
	text-align: center;
	color: black;
	font-weight: bold;
	font-size: 15px;
	line-height: 20px;
	}
	
.links div p	{
	padding: .2em 1.5em .4em 0;
	}
	
.links div p#mess	{
	padding: .2em 1.5em 0 0;
	}
	
div#body	{
	line-height: 1.5em;
	width: 7in;
	margin: auto;
	padding-bottom: 20px;
	}
	
#body p	{
	color: #555;
	padding-top: 30px;
	line-height: 20px;
	}

	
#body a	{
	display: block;
	color: #D10A0A;
	margin: 1em 3em;
	background-repeat: no-repeat;
	background-position: top right;
	padding: 1em 1em;
	border: 1px dotted #888;
	font-weight: bold;
	font-size: 15px;
	text-decoration: none;
	line-height: 26px;
	background: #FFFFE5;
	}

#body span	{
	color: #555;
	font-weight: normal;
	font-size: 14px;
	}

#body span.number	{
	display: block;
	float: right;
	color: #000;
	font-weight: normal;
	border: 1px solid #888;
	padding: 0 6px;
	font-weight: bold;
	margin-left: 15px;
	font-size: .9em;
	background: #fff;
	}
	
#actions	{
	display: none;
	}

</style>



</head>

<body id="or_print_report">


<div id="container">

<div id="top">
    <div id="content">
        <!-- ######### Top Body  ##########################--> 
        <div id="top_body">
            <p id="title">
            <img src="/r/build/images/814a4152b3aca062da5c4bcdcd07c82ecb_tiiuklogo.gif" id="logo" width="60">
            TurnitinUK Originality Report
            </p>
                <div class="general_info">
                    <p>
                        <span>Automatic Reading of Building Design Documents</span>
                        
                        by MingLiu
                        
                    </p>
                    <p>
                        From paper826 (paper)
                    </p>
                    <ul>
                        <li>Processed on 05-Sep-2020  3:36 AM BST</li>
                        <li>ID: 133064681</li>
                        <li>Word Count: 14688</li>
                    </ul>
                </div>
                <div class="similarity_box">
                    <div class="overall_similarity">
                        <div class="color_box yellow">&nbsp;</div>
                        <div class="similarity_title">Similarity Index</div>
                        <div class="similarity_percent">38%</div>
                    </div>
                    <div class="similarity_by_source">
                        <div class="similarity_title">Similarity by Source</div>
                        <dl>
                            <dt>Internet&nbsp;Sources:</dt>
                            <dd>7%</dd>
                            <div class="clear"></div>
                            <dt>Publications:</dt>
                            <dd>4%</dd>
                            <div class="clear"></div>
                            <dt>Student&nbsp;Papers:</dt>
                            <dd>37%</dd>
                            <div class="clear"></div>
                        </dl>
                    </div>
                </div>
                <div class="clear"></div>
                                 
        </div>
        <!-- ######### END Top Body  ##########################--> 
    </div>
</div>

<div class="divider">sources:</div>

<div class="links">

	<div>
	<div class="number-l">1</div>
	<p>34% match (student papers from 27-May-2020)</p>

	<a href="/paperInfo.asp?r=91.2178570957728&svr=25&lang=en_us&oid=oid:2:630550565&perc=34">Submitted to University of Sheffield on 2020-05-27</a>

	</div>
	<div>
	<div class="number-l">2</div>
	<p>1% match (student papers from 10-Sep-2019)</p>

	<a href="/paperInfo.asp?r=91.2178570957728&svr=25&lang=en_us&oid=oid:2:606350286&perc=1">Submitted to University of Sheffield on 2019-09-10</a>

	</div>
	<div>
	<div class="number-l">3</div>
	<p>1% match (student papers from 02-May-2020)</p>

	<a href="/paperInfo.asp?r=91.2178570957728&svr=25&lang=en_us&oid=oid:2:626228305&perc=1">Submitted to University of Sheffield on 2020-05-02</a>

	</div>
	<div>
	<div class="number-l">4</div>
	<p>< 1% match (student papers from 13-May-2020)</p>

	<a href="/paperInfo.asp?r=91.2178570957728&svr=25&lang=en_us&oid=oid:2:628018575&perc=0">Submitted to University of Sheffield on 2020-05-13</a>

	</div>
	<div>
	<div class="number-l">5</div>
	<p>< 1% match (Internet from 27-Dec-2010)</p>

	<a href="http://hazydaze.soundingblue.com/2005/12/page/2/">http://hazydaze.soundingblue.com/2005/12/page/2/</a>

	</div>
	<div>
	<div class="number-l">6</div>
	<p>< 1% match (Internet from 29-Aug-2020)</p>

	<a href="https://nanonets.com/blog/ocr-with-tesseract/">https://nanonets.com/blog/ocr-with-tesseract/</a>

	</div>
	<div>
	<div class="number-l">7</div>
	<p>< 1% match (Internet from 26-Jun-2019)</p>

	<a href="https://docs.wallarm.com/en/glossary-en.html">https://docs.wallarm.com/en/glossary-en.html</a>

	</div>
	<div>
	<div class="number-l">8</div>
	<p>< 1% match (student papers from 11-Sep-2013)</p>

	<a href="/paperInfo.asp?r=91.2178570957728&svr=25&lang=en_us&oid=oid:1:350913196&perc=0">Submitted to Study Group Australia on 2013-09-11</a>

	</div>
	<div>
	<div class="number-l">9</div>
	<p>< 1% match (Internet from 20-Apr-2020)</p>

	<a href="https://fr.scribd.com/document/330172395/c">https://fr.scribd.com/document/330172395/c</a>

	</div>
	<div>
	<div class="number-l">10</div>
	<p>< 1% match (Internet from 10-Aug-2017)</p>

	<a href="https://eprints.qut.edu.au/106914/1/Jonathan_Davis_Thesis.pdf">https://eprints.qut.edu.au/106914/1/Jonathan_Davis_Thesis.pdf</a>

	</div>
	<div>
	<div class="number-l">11</div>
	<p>< 1% match (Internet from 24-Dec-2018)</p>

	<a href="https://elib.uni-stuttgart.de/bitstream/11682/9567/1/Thesis_Seibold_348.pdf">https://elib.uni-stuttgart.de/bitstream/11682/9567/1/Thesis_Seibold_348.pdf</a>

	</div>
	<div>
	<div class="number-l">12</div>
	<p>< 1% match (publications)</p>

	<a href="http://link.springer.com/10.1007/978-981-15-1301-5">"Smart City and Informatization", Springer Science and Business Media LLC, 2019</a>

	</div>
	<div>
	<div class="number-l">13</div>
	<p>< 1% match (publications)</p>

	<a href="https://ieeexplore.ieee.org/document/9178372/">Norrawit Tonmitr, Takahiko Mori, Masashi Takami, Akira Yonesu, Nobuya Hayashi. "Time-Modulated LF-Microwave Hybrid Plasma for Surface Sterilization", IEEE Transactions on Plasma Science, 2020</a>

	</div>
	<div>
	<div class="number-l">14</div>
	<p>< 1% match (Internet from 28-Feb-2019)</p>

	<a href="https://link.springer.com/article/10.1007/s13042-012-0079-7">https://link.springer.com/article/10.1007/s13042-012-0079-7</a>

	</div>
	<div>
	<div class="number-l">15</div>
	<p>< 1% match (Internet from 06-Jun-2017)</p>

	<a href="http://isee.sysu.edu.cn/~zhwshi/Research/PreprintVersion/PAKCL.pdf">http://isee.sysu.edu.cn/~zhwshi/Research/PreprintVersion/PAKCL.pdf</a>

	</div>
	<div>
	<div class="number-l">16</div>
	<p>< 1% match (Internet from 02-Jul-2020)</p>

	<a href="https://dspace.mit.edu/bitstream/handle/1721.1/104565/958660378-MIT.pdf?isAllowed=y&sequence=1">https://dspace.mit.edu/bitstream/handle/1721.1/104565/958660378-MIT.pdf?isAllowed=y&sequence=1</a>

	</div>
	<div>
	<div class="number-l">17</div>
	<p>< 1% match (Internet from 30-Jan-2020)</p>

	<a href="https://link.springer.com/article/10.1007%2Fs10586-018-1799-6">https://link.springer.com/article/10.1007%2Fs10586-018-1799-6</a>

	</div>
	<div>
	<div class="number-l">18</div>
	<p>< 1% match (Internet from 14-Jul-2019)</p>

	<a href="https://oi.qizy.tech/?cat=224">https://oi.qizy.tech/?cat=224</a>

	</div>
	<div>
	<div class="number-l">19</div>
	<p>< 1% match (Internet from 28-Aug-2020)</p>

	<a href="https://pastel.archives-ouvertes.fr/pastel-00977514/file/TH2013PEST1094_complete.pdf">https://pastel.archives-ouvertes.fr/pastel-00977514/file/TH2013PEST1094_complete.pdf</a>

	</div>
	<div>
	<div class="number-l">20</div>
	<p>< 1% match (Internet from 04-Aug-2020)</p>

	<a href="https://mafiadoc.com/democracy-in-development-bibsys-brage_59c539ce1723dd291c573739.html">https://mafiadoc.com/democracy-in-development-bibsys-brage_59c539ce1723dd291c573739.html</a>

	</div>
	<div>
	<div class="number-l">21</div>
	<p>< 1% match (Internet from 09-Jun-2020)</p>

	<a href="https://bloggerbrothers.com/2017/12/09/turn-on-a-lamp-with-a-gesture-ir-cam-image-processing/comment-page-2/">https://bloggerbrothers.com/2017/12/09/turn-on-a-lamp-with-a-gesture-ir-cam-image-processing/comment-page-2/</a>

	</div>
	<div>
	<div class="number-l">22</div>
	<p>< 1% match (Internet from 26-Jun-2020)</p>

	<a href="https://slidelegend.com/visual-c-in-21-days-second-edtion-angelfire_5a9c3ba51723ddda3590b13f.html">https://slidelegend.com/visual-c-in-21-days-second-edtion-angelfire_5a9c3ba51723ddda3590b13f.html</a>

	</div>
	<div>
	<div class="number-l">23</div>
	<p>< 1% match (Internet from 27-Apr-2016)</p>

	<a href="https://realpython.com/blog/python/setting-up-a-simple-ocr-server/">https://realpython.com/blog/python/setting-up-a-simple-ocr-server/</a>

	</div>
	<div>
	<div class="number-l">24</div>
	<p>< 1% match (publications)</p>

	<a href="http://link.springer.com/10.1007/978-3-319-91253-0">"Artificial Intelligence and Soft Computing", Springer Science and Business Media LLC, 2018</a>

	</div>
	<div id="last">
	<div class="number-l">25</div>
	<p>< 1% match (publications)</p>

	<a href="http://link.springer.com/10.1007/978-81-322-1665-0">"Intelligent Computing, Networking, and Informatics", Springer Science and Business Media LLC, 2014</a>

	</div>

</div>



<div class="divider">paper text:</div>
<div id="body">
<a href="javascript:openDSC(630550565, 2, '0');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="0" name="1" ><span class="b-ref">1</span>University of Sheffield Automatic Reading of Building Design Documents Ming Liu Supervisor: Dr Ramsay Taylor COM6905 Research Methods and Professional Issues This report is submitted in partial fulfilment of the<span> requirement </span>for the degree of MSc in Computer Science With Speech and Language Processing by Ming Liu in the Department of Computer Science<span> September 5, </span>2020 Declaration All sentences or passages quoted in this report from other people’s work have been specifically acknowledged by clear cross-referencing to author, work and page(s). Any illustrations that are not the work of the author of this report have been used with the explicit permission of the originator and are specifically acknowledged. I understand that failure to do this amounts to plagiarism and will be considered grounds for failure in this project and the degree examination as a whole. Name: Ming Liu Signature: Date:<span> September 5, </span>2020 Abstract With a large number of data comes from a modern smart building every day, how to collect, store and analyse these data can be a problem. In this work, we only put our attention on a small part of the analysis process. Before doing the analysis, we need to figure out the relationship between Rooms and Sensors. Therefore, to be more specific, this work proposes an extraction pipeline, which can help to extract the relationship between Rooms and Sensors from the building drawings. By partitioning the extraction process into three parts: Text and Coordinate Extraction, Relationship Extraction and Evaluation, fancy results can be achieved.</a> i <a href="javascript:openDSC(628018575, 2, '12569');" onmouseover="doRollover(4);" onmouseout="undoRollover(4);" id="12569" name="4" ><span class="b-ref">4</span>COVID-19 Impact Statement The lockdown imposed because of COVID-19 caused additional challenges for the completion of this project. In the second semester of the project, the University switched to online delivery of all teaching, and university buildings were closed. All project meetings were shifted to email correspondence and video meetings. ii</a> Acknowledgement First of all, I would like to thank my parents, two elder sisters, little nephew and an unborn baby nephew for motivating me to keep working hard. While studying at the University of Sheffield, they gave me generous support and encouraged me to keep moving forward. At the same time, <a href="javascript:openDSC(1741207011, 2909, '24395');" onmouseover="doRollover(10);" onmouseout="undoRollover(10);" id="24395" name="10" ><span class="b-ref">10</span>I would also like to thank my supervisor, Dr<span> Ramsay Taylor, </span>for his<span> patient guidance, encouragement </span>and</a> support in this project, especially during this global pandemic periodic. Meanwhile, <a href="javascript:openDSC(3169147702, 3788, '25935');" onmouseover="doRollover(16);" onmouseout="undoRollover(16);" id="25935" name="16" ><span class="b-ref">16</span>I would also like to thank my friends and</a> anyone I met in Sheffield. Thanks to all the teachers and staffs who gave me help and convenience during my studies. Finally, I want to thank my ex-girlfriend for being with me in my toughest moments. If you ask me how I feel about you now, then what I want to tell you is that even if we haven’t chatted for a long time, haven’t spoken or even broken all contact, you are still a very, very important person to me. If you ask me what I want to say to you now, then I want to tell you that I like the marriage vows in <a href="javascript:openDSC(1746160399, 772, '24657');" onmouseover="doRollover(5);" onmouseout="undoRollover(5);" id="24657" name="5" ><span class="b-ref">5</span>”Corpse Bride”: ”With this hand I will lift your sorrows. Your cup will never be empty, for I will be your wine. With this candle, I will light your way into darkness. With this ring, I ask you to be mine.” In</a> fact, I don’t have many pursuits in my life. Every New Year, I am looking forward to it, and hope that all the regrets this year will be the preparation for the surprise next year. <a href="javascript:openDSC(630550565, 2, '11');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="11" name="1" ><span class="b-ref">1</span>Contents 1 Introduction 1 1.<span> 1 </span>Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1<span> 1.2 </span>Aims and Objectives<span> ................................................................................................................... 2 1.3 </span>Overview ..................................................................................................................................... 2<span> 2 </span>Literature Survey<span> ........................................................................................................................ 3 2.1 </span>Text and coordinate Extraction Tools</a> ....................................................................................... 3 iii 2.1.1 PDFMiner in Python ................................................................................................................ 3 2.1.1.1 The Classes in PDFMiner...................................................................................................... 3 2.1.1.2 The Structure of PDF in PDFMiner ...................................................................................... 4 2.1.1.3 Text Extraction Notes in PDFMiner..................................................................................... 4 2.1.2 Apache PDFBoxr in Java ........................................................................................................... 5 2.1.2.1 Text Extraction Notes in Apache PDFBoxr .......................................................................... 5 2.1.3 OpenCV OCR with Tesseract in Python .................................................................................. 6 2.1.3.1 OpenCV OCR .......................................................................................................................... 6 2.1.3.2 Tesseract ............................................................................................................................... 7 2.1.3.3 Workflow............................................................................................................................... 7 2.2 Relationship Extraction Methodologies .................................................................................... 8 2.2.1 Euclidean Metric ...................................................................................................................... 8 2.2.1.1 Mathematical Representation.............................................................................................. 8 2.2.1.2 Euclidean Distance Matrices (EDM) .................................................................................... 8 2.2.2 K-Means Clustering.................................................................................................................. 9 2.2.2.1 The Process of K-Means Clustering ..................................................................................... 9 2.2.2.2 Mathematical Representation............................................................................................ 10 2.3 Evaluation Algorithms.............................................................................................................. 11 2.3.1 Purity ...................................................................................................................................... 11 <a href="javascript:openDSC(3481879702, 3265, '27117');" onmouseover="doRollover(11);" onmouseout="undoRollover(11);" id="27117" name="11" ><span class="b-ref">11</span>2.3.2 Rand Index ............................................................................................................................. 12 2.3.3 F-<span> measure............................................................................................................................... 13 </span>2.</a> 4 Summary ................................................................................................................................... 13 iv v CONTENTS 3 Requirements and <a href="javascript:openDSC(630550565, 2, '34');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="34" name="1" ><span class="b-ref">1</span>Analysis 3.1 Project Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Project Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Function Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.4 Function Improvement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.5 Ethical, Professional and Legal Issues . . . . . . . . . . . . . . . . . . . . . . 4 Planning 4.1 Risk Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Project Breakdown Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Project Plan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5</a> Implementation, Assembly, Test and Evaluation 5.1 5.1.1 5.1.2 5.1.1.1 5.1.1.2 5.1.1.3 5.1.2.1 5.1.2.2 5.1.2.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Text and Coordinates Extraction . . . . . . . . . . . . . . . . . . . . . PDFMiner Extractor Implementation . . . . . . . . . . . . . PDFBox Extractor Implementation . . . . . . . . . . . . . . OpenCV Extractor Implementation . . . . . . . . . . . . . . Relationship Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . Euclidean Distance Implementation . . . . . . . . . . . . . . K-Means Clustering Implementation . . . . . . . . . . . . . . Auxiliary Relationship Extraction . . . . . . . . . . . . . . . 5.2 5.3 5.2.1 5.2.2 5.3.1 5.3.2 5.3.3 5.3.4 5.3.1.1 5.3.2.1 5.3.3.1 Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Benchmark and Result . . . . . . . . . . . . . . . . . . . . . . . . . . . The Accuracy Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Purity Method Implementation . . . . . . . . . . . . . . . . . . . . . . Purity Code . . . . . . . . . . . . . . . . . . . . . . . . . . . Rand Index Method Implementation . . . . . . . . . . . . . . . . . . . Rand Index Code . . . . . . . . . . . . . . . . . . . . . . . . F-measure Method Implementation . . . . . . . . . . . . . . . . . . . . F-measure Code . . . . . . . . . . . . . . . . . . . . . . . . . Evaluation Methods Results . . . . . . . . . . . . . . . . . . . . . . . . 5.4 Relationship Extraction Pipeline Assembly . . . . . . . . . . . . . . . . . . . 5.4.1 Relationship Extraction Pipeline Structure . . . . . . . . . . . . . . . 5.4.2 Linking Between Extractors . . . . . . . . . . . . . . . . . . . . . . . . 6 Achievements and Conclusions 6.1 Findings and Goals Achievements . . . . . . . . . . . . . . . . . . . . . . . . . 6.2 Further work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.2.1 Improvement in OpenCV Room Divider . . . . . . . . . . . . . . . . . 6.2.2 Improvement in Relationship Extraction . . . . . . . . . . . . . . . . . vi 14 14 15 15 16 16 17 17 18 19 20 20 20 22 25 27 31 31 34 36 40 40 40 41 41 41 43 44 45 45 48 48 49 49 51 51 51 51 52 CONTENTS vii 6.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 Appendices 56 A An Appendix of Project Gantt Chart 57 <a href="javascript:openDSC(630550565, 2, '35');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="35" name="1" ><span class="b-ref">1</span>List of Figures 2.1 The Association Between Five Classes in PDFMiner . . . . . . . . . . . . . . 2.2 The Tree Structure of Text Classes in PDFMiner . . . . . . . . . . . . . . . . 2.3 The Layout of Text Classes in PDFMiner . . . . . . . . . . . . . . . . . . . . 2.4 The Layout of Text Classes in PDFMiner . . . . . . . . . . . . . . . . . . . . 2.5 OpenCV OCR with Tesseract . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.6 The Calculation Process Legend of Euclidean Distance . . . . . . . . . . . . . 2.7 An Example of Euclidean Distance Matrices Heatmap . . . . . . . . . . . . . 3.1 The Relationship Extraction Pipeline . . . . . . . . . . . . . . . . . . . . . . . 4.1 The Project Breakdown Structure</a> ........................ 5.1 A Sample of Monochrome Building Drawing . . . . . . . . . . . . . . . . . . . 5.2 A Sample of Colourful Building Drawing . . . . . . . . . . . . . . . . . . . . . 5.3 The Actual Text: ’S/D.29/01’ . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4 The Actual Text: ’BREAKOUT ROOM 3.8’ . . . . . . . . . . . . . . . . . . 5.5 The Actual Text: ’200∅’ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.6 The Actual Text: ’ATT/E.39/1’ . . . . . . . . . . . . . . . . . . . . . . . . . 5.7 The Warning Messages of Unknown Font or Encoding . . . . . . . . . . . . . 5.8 The Actual Text: ’E.06 BREAKOUT ROOM 3.7 14.63 m2 8 Seats’ . . . . . . 5.9 A Part of Extraction Result by OpenCV and Tesseract . . . . . . . . . . . . . 5.10 The Unrecognisable Covered Text . . . . . . . . . . . . . . . . . . . . . . . . . 5.11 The Relationship Extraction Result of E.06 . . . . . . . . . . . . . . . . . . . 5.12 E.31 - E.32 - E.33 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.13 A Example of Building Drawing Picture . . . . . . . . . . . . . . . . . . . . . 5.14 The Result of Building Drawing By Taking Room Range Extraction Pipeline 5.15 A Terrible Result of Room Extraction . . . . . . . . . . . . . . . . . . . . . . 5.16 A Range of Room: E.28 FEMALE TOILETS . . . . . . . . . . . . . . . . . . 5.17 Relationship Extraction Pipeline Structure . . . . . . . . . . . . . . . . . . . 4 5 6 7 9 10 12 14 18 21 21 23 24 24 25 27 27 30 30 34 36 38 38 39 39 48 viii <a href="javascript:openDSC(630550565, 2, '65');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="65" name="1" ><span class="b-ref">1</span>List of Tables 2.1 Parameters for Command-line Tool in Apache<span> PDFBoxr . . . . . . . . . . . 8 </span>2.<span> 2 </span>An Example of Euclidean Distance Matrices<span> . . . . . . . . . . . . . . . . . . . 11 3.1 </span>The Function Requirements<span> . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 4.1 </span>A List of Risks<span> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 4.2 </span>The Main Objectives and Dates</a> . . . . . . . . . . . . . . . . . . . . . . . . . . 19 5.1 A Benchmark Result of File 34676-M57-0302-lss7 . . . . . . . . . . . . . . . 41 5.2 A Room Extraction Result of File 34676-M57-0302-lss7 . . . . . . . . . . . . 42 6.1 The Function Achievements . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 ix Listings 5.1 Extraction Code Using OpenCV with Tesseract . . . . . . . . . . . . . . . . . 5.2 Relationship Extraction Code by Calculating Distance . . . . . . . . . . . . . 5.3 A Function of Calculating Euclidean Distance . . . . . . . . . . . . . . . . . . 5.4 Extraction Code Using OpenCV with Tesseract . . . . . . . . . . . . . . . . . 5.5 A Function of Calculating Purity . . . . . . . . . . . . . . . . . . . . . . . . . 5.6 A Function of Calculating Rand Index . . . . . . . . . . . . . . . . . . . . . . 5.7 A Function of Calculating F-measure . . . . . . . . . . . . . . . . . . . . . . . 28 31 32 34 42 44 45 x Chapter 1 Introduction <a href="javascript:openDSC(630550565, 2, '82');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="82" name="1" ><span class="b-ref">1</span>Nowadays, indoors lives take us the most time (Jia et al., 2018). The quality of our lives relies largely on building construction. A modern building with hardware and software, as a shelter, keeps us from being affected by the outside surroundings and makes our life better. (Nimlyat, 2018). As a modern building, the basic elements like bricks and cement are not the only characters, the sensors are more important features instead. When a building was designed as a ’Smart Building’, it means a number of services are recorded for tracking, analysing and improving. Omarov et al. (2017) propose some control methods on HVAC<span> 1systems, </span>which can improve the quality in the room, as well as present an enhanced comfort presented to people. One study, which is based on the hospital, also shows that the positive quality indoors circumstances on patients could result in an affirmative meaning during regain (Nimlyat, 2018). Therefore, the smarter building, the better the life we enjoy. With the rapid<span> increase </span>of data we had from these sensors, more scenarios can be detected so that the building can adjust its power supply to save energy. That is why the technology we applied to buildings also plays a key role in lowering emissions (Tadokoro et al., 2014). 1.1 Problem Statement The Diamond is a modern and high-tech building, which provides us with a suitable, convenient and enjoyable learning space by running a massive range of lighting, heating, networking, electrical and other services. These services will produce an abundance of data every day. By combining these dynamic data with static building drawings, the status of a specific room can</a> 1 Heating, ventilation, and air conditioning <a href="javascript:openDSC(630550565, 2, '85');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="85" name="1" ><span class="b-ref">1</span>be presented, as well as the related rooms. Therefore, how we extract the relationship between rooms and rooms as well as rooms and sensors can be a difficulty.</a> 1 xii 2 <a href="javascript:openDSC(630550565, 2, '89');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="89" name="1" ><span class="b-ref">1</span>CHAPTER 1. INTRODUCTION 1.2 Aims and<span> Objectives </span>Our ultimate goal is to build a system, which automatically reads data and drawings, and reports to us what happened in a specific room at a specific time. However, it is a tough job. So this work aims to figure out the relationship between rooms and sensors through all the static building drawings. More specifically, it extracts the text and coordinate from drawings. After passing the drawings to the classifier, text and coordinate can be split into Room label or Sensor label respectively. At last, the relationship between rooms and sensors in terms of coordinate will be discovered by calculating the distances, which is similar to the K-Means clustering method (This is described in detail in Section 2.2.2) classifying data points into unrelated groups so that the data in the same group show similarity, whereas the data in the different group present more distinction (Na et al., 2010). Besides, diverse ways, like PDFMiner in Python and Apache<span> PDFBoxr </span>in Java, are taken in this work for text and coordinate extraction. (These are described in detail in Section 2.1.1.<span> 1 </span>and 2.1.2) During the relation extraction process, it takes distance calculation or K-Means clustering methods to assess performance. It is critical to mention the metrics of evaluation. The purity, for example, is used to assess the extent for a cluster has a single class (Sanderson, 2010). Also, Rand (1971a) raises a method called Rand index, which calculates the similarity between the result coming from our clustering algorithm and the standard classifications. More significantly, this work is a fresh approach for relationship extraction in building drawings, and thereby, it is also essential to confirm the applicability of this approach in this area. 1.3 Overview For chapter 2, it reviews some tools, methodologies and algorithms used in this work which provides some basic knowledge overall. In addition, chapter 3 contains some details in implementing the process as well as some requirements in which would be involved. What is more, Ethical, Professional and Legal Issues will be addressed in this chapter. After that, chapter 4 will promote the working plan. More importantly, the risk will be analysed ahead. In the last chapter, the conclusion of the whole work will be done. The bibliographies and appendices will be provided in the end. Chapter 2 Literature Survey This work is made up of three sub-tasks: Text and coordinate Extraction, Relationship Extraction and Evaluation. Some tools, methodologies and algorithms should be used to solving these tasks. 2.1 Text and coordinate Extraction Tools In this section, some tools will be introduced to extract the text and coordinate from the PDF files of building drawings. To begin with, all the data of this work comes from PDF files. Even though the PDF file is called the PDF Document, it is different from HTML or XML documents in terms of its structure. Most HTML or XML documents are structural documents, which show you where a sentence or a picture is, while the PDF file is more like a graph with coordinate. As the developer, Shinyama (2015) says ”PDF is evil”. 2.1.1 PDFMiner in Python The PDFMiner, as an open-source PDF-to-text converter, can extract information from PDFs and regenerate other types of formats.</a> 2.1.1.1 The <a href="javascript:openDSC(630550565, 2, '110');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="110" name="1" ><span class="b-ref">1</span>Classes in PDFMiner There are at least five classes involved in the process of extracting a PDF file.<span> PDFDocument </span>class stores the data which is drawn from the PDFParser class. In terms of the PDFResourceManager class, which is used to process the fonts and images, the PDFPageInterpreter class can handle the page content. At last, the result produced from the above mentioned four classes will be transmuted by the PDFDevice class to whatsoever types. The connection between these five classes is illustrated in Figure 2.1. 3<span> CHAPTER </span>2.</a> LITERATURE SURVEY 4 Figure <a href="javascript:openDSC(630550565, 2, '36');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="36" name="1" ><span class="b-ref">1</span>2.1: The Association Between Five Classes in PDFMiner 2.<span> 1.1.2 </span>The</a><a href="javascript:openDSC(630550565, 2, '118');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="118" name="1" ><span class="b-ref">1</span>Structure of PDF in PDFMiner This work only touches on the text. Figure 2.2 is the structure of Text classes in PDFMiner. Figure 2.3 is the practical layout where these Text classes are presented. LTPage: It means the whole page and contains LTTextBox, LTFigure and LTLine or other objects. Nevertheless, this work does not care about the other types of object except for text. LTTextBox: LTTextBox is a square area where a bunch of LTTextLine are included. However, the square area is not a logical border, although it is formed by the analysis of the PDF file. LTTextLine: It has a group of LTChar objects where these LTChar objects are in the same line. LTChar, LTText: They are similar to each other, which holds a character.</a> 2.1.1.3 <a href="javascript:openDSC(630550565, 2, '125');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="125" name="1" ><span class="b-ref">1</span>Text Extraction Notes in PDFMiner In addition to writing code with PDFMiner library, there are two utilities named pdf2txt.py and dumppdf.py. In the course of extracting text through PDFMiner, there are some parameters that need to be noticed. M, L, W are significant parameters. M means the margin of chars, L means the margin of lines and W means the margin of words. M = 2.0, L = 0.5, and W = 0.1 are the default values, individually. Besides, Figure 2.4 shows the layout of Text classes clearly. To adopt different PDF files, each value of margins should be appropriately chosen. Figure 2.2: The Tree Structure of Text Classes in PDFMiner 2.1.2 Apache<span> PDFBoxr </span>in Java Apache<span> PDFBoxr </span>is another open-source tool written in Java, which has the similar functionality with PDFMiner, it provides eight features Extract Text, Split &amp; Merge, Preflight, Print, Save as Image, Create PDFs and Signing(<span> PDFBoxr, </span>2010). For more information, you can refer to Apache<span> PDFBoxr </span>(https://pdfbox.apache.org/).</a> 2.1.2.1 <a href="javascript:openDSC(630550565, 2, '136');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="136" name="1" ><span class="b-ref">1</span>Text Extraction Notes in Apache<span> PDFBoxr </span>In addition to jar library, the Apache<span> PDFBoxr </span>provides a command-line tool same as PDFMiner. This paper only focuses on ExtractText in which all the text inside the PDF file will be extracted. The usage of the command-line tool is shown as follows. Table 2.1 provides a part of the parameters for [OPTION] Usage: java -jar pdfbox-app-2.y.z.jar ExtractText [OPTIONS] &lt;inputfile&gt;[Text file] Apart from that, when using java 8 or java 9, the version can not be higher than 1.8.0 191 or 1.9.0.4 respectively. Figure 2.3: The Layout of Text Classes in PDFMiner 2.1.3 OpenCV OCR with Tesseract in Python In this sub-section, there is a combined approach, which is different from PDFMiner or Apache<span> PDFBoxr, </span>to identify words. First and foremost, it is not necessary to read the PDF files and extract information from them, while it uses OCR<span> 2 </span>to detect words. What is more, by taking EAST 2 deep learning model in OpenCV, all possible text areas can be detected. After that, all text areas containing text will be passed to Tesseract to recognise all text.</a> 2.1.3.1 <a href="javascript:openDSC(630550565, 2, '146');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="146" name="1" ><span class="b-ref">1</span>OpenCV OCR OpenCV is an open-source, and a collection of function libraries focusing on solving<span> realtime </span>computer vision tasks (Pulli et al., 2012). You can find more details about OpenCV (https://opencv.org/) for reference. Based on the teamwork of Zhou et al. (2017), EAST algorithm is implemented as an OCR module in OpenCV. Zhou et al. (2017) state that EAST is an uncomplicated but formidable pipeline, which provides a text detection with swift speed and high precision in actual scenarios.</a> Figure <a href="javascript:openDSC(630550565, 2, '60');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="60" name="1" ><span class="b-ref">1</span>2.4: The Layout of Text Classes in PDFMiner 2</a> Optical <a href="javascript:openDSC(630550565, 2, '148');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="148" name="1" ><span class="b-ref">1</span>character recognition or optical character reader 2An Efficient and Accurate Scene Text Detector.</a> 2.1.3.2 <a href="javascript:openDSC(630550565, 2, '153');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="153" name="1" ><span class="b-ref">1</span>Tesseract Tesseract is a free and open-source OCR engine which can be used in different platforms(Kay, 2007). Ever since 2006, it had become the most accurate OCR engine in the world sponsored by Google(Vincent and Lead, 2007). Indeed, the Tesseract engine had shown its talent in 1995. In the work of Rice et al. (1995), they report that the accuracy of Tesseract reaches the top three among all OCR engines. With the development of Tesseract, it can<span> recognise </span>over 100 languages now. What is more, it could be retrained to adapt to other languages as long as sufficient data is provided.</a> 2.1.3.3 <a href="javascript:openDSC(630550565, 2, '155');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="155" name="1" ><span class="b-ref">1</span>Workflow Figure 2.5 shows the workflow of text recognition by using OpenCV OCR and Tesseract. For the first step, PDF files should be converted to images so that they can be processed by the EAST algorithm in OpenCV. Then, the EAST will identify the regions of text and store it. Next, these regions called ROIs 3 will be put into Tesseract. Finally, The Tesseract will show the result of texts.</a> Parameters Default Description 3 A <a href="javascript:openDSC(630550565, 2, '156');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="156" name="1" ><span class="b-ref">1</span>region of interest, are samples within a data set identified for a particular purpose. -password EMPTY The password of PDF file; it is empty by default. -sort False If the value is True, it will sort result before output. -html False If the value is True, it will generate an HTML file instead of pure text. Table 2.1: Parameters for Command-line Tool in Apache<span> PDFBoxr </span>2.2 Relationship Extraction Methodologies In this section, a few methodologies in extracting relationship between rooms and sensors will be present. 2.2.1 Euclidean Metric Before introducing the Euclidean metric, the Euclidean space must be talked ahead. Because Euclidean metrics or Euclidean distance is a measurement between two data points among Euclidean space. For the more, there are many types of positive number dimension in Euclidean spaces. Our world could be a three-dimensional space where we can apply the Euclidean metric for measurement and compare it with others.</a> 2.2.1.1 <a href="javascript:openDSC(630550565, 2, '163');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="163" name="1" ><span class="b-ref">1</span>Mathematical Representation The Euclidean distance is defined by the length between point a and point b. this paper only<span> considers </span>the 2-dimensional Euclidean space, which is the Euclidean plane. Figure 2.6 shows how distance is represented. Equation 2.1 gives the formula of computation.<span> q </span>d(a,b) = (a1 − b1)2 + (a2 − b2)2 (2.1)</a><a href="javascript:openDSC(630550565, 2, '166');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="166" name="1" ><span class="b-ref">1</span>2.2.1.<span> 2 </span>Euclidean Distance Matrices (EDM) In recent papers, the Euclidean Distance Matrices, or EDMs, come into vogue, and the most basic academic research is carried out by Young and Householder (1938). For example, Table 2.2 is a Euclidean Distance Matrices. The symmetric structure appears, which could be converted to heatmap 2.7 so that you can see it more clearly. With these distance between rooms and sensors, we can simply classify certain sensors to one category, which belongs to a specific Room. Figure 2.5: OpenCV OCR with Tesseract 2.2.2 K-Means Clustering In 1967, The ”k-means” was initially created by MacQueen et al. Nowadays, K-Means clustering is an iterative and unsupervised learning algorithm, which enjoys a high reputation around the world (MacQueen et al., 1967). Its aims at dividing datasets into Kpre-defined subsets containing no intersection data. What is more, it is usually in big data, machine learning and data mining (Lee et al., 2011). In real society, this algorithm still has its limitation, and thereby some researchers extend this algorithm with background knowledge (Wagstaff et al., 2001) or domain knowledge (Huang, 1998) so that it could be more suitable for an actual situation. In addition, other groups apply this algorithm in some special areas, particularly in detecting schizophrenia (Lee et al., 2011). Just to<span> emphasise </span>the point above, what we use here is the standard algorithm named the least squared Euclidean distance.</a> 2.2.2.1 The <a href="javascript:openDSC(630550565, 2, '175');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="175" name="1" ><span class="b-ref">1</span>Process of K-Means Clustering Based on the distance between centres and data points, K-Means<span> tries </span>to split all datasets into Kpre-defined clusters so that the sum of distance within-cluster can be the smallest. Importantly, it is up to how we define the distance. The process of K-Means Clustering is illustrated below: Figure 2.6: The Calculation Process Legend of Euclidean Distance (s1) Firstly, the value of K should be set and then randomly choose data points in the number of K as initial, where K is lower than the size of the whole datasets centres. (s2) Then, by calculating the distance between each centre points with all data points, we rearrange these data points into different groups where each group hold the smallest sum of distances. (s3) Next, recalculating the new group centre points, which may not be an existing point. (s4) Finally, by repeating the process from step (s2) until there are no changes in all centre points, the process comes to an end.</a> 2.2.2.2 <a href="javascript:openDSC(630550565, 2, '178');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="178" name="1" ><span class="b-ref">1</span>Mathematical Representation S contains k sets, where S = S1,S2,...,Sk. If all the data points x are given by (x1,x2,...,xn), and each x is made up of n-dimensional vectors, our goal is to figure out the equation 2.2 below. aa bb cc dd ee ff aa 0 201 188 99 130 211 bb 201 0 65 130 89 133 cc 188 65 0 121 111 104 dd 99 130 121 0 30 88 dd 130 89 111 30 0 115 dd 211 133 104 88 115 0 Table 2.2: An Example of Euclidean Distance Matrices k k</a> argminXX kx − µik2 = argminX|Si|VarSi s s i=1 x∈Si i=1 k = argmin s (2.2) i=1 x,y∈Si <a href="javascript:openDSC(630550565, 2, '180');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="180" name="1" ><span class="b-ref">1</span>where µi is the mean of points in Si. 2.3 Evaluation Algorithms For the last section, it shows two types of evaluation algorithms in this work. 2.3.1 Purity Purity is a common and primary metric, which is often used for evaluating the performance of the clustering result. In general, the more considerable value of purity means the higher<span> number </span>of clustering (Sripada and Rao, 2011). The formula of purity can be defined as Equation 2.3.</a> (2.3) <a href="javascript:openDSC(630550565, 2, '182');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="182" name="1" ><span class="b-ref">1</span>Where M is a series of clusters, D means a range of classes and N represents the number of data points in each group. However, when a lopsided result comes into purity algorithm, Figure 2.7: An Example of Euclidean Distance Matrices Heatmap it becomes a disaster. For instance, supposing there are two clusters with 100 data points, it always gives a high purity value even if there is one cluster contains 98 data points, and the other only has 2. 2.3.2 Rand Index Rand (1971b) proposes an algorithm, which is used for evaluating the quality of clustering by comparing the similarity between the result coming from our clustering algorithm and the standard classifications. Given the<span> number </span>of true positives<span> TP, </span>true negatives<span> TN, </span>false positives<span> FP </span>and false negatives<span> FN, </span>the equation is described as below:</a><a href="javascript:openDSC(630550565, 2, '190');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="190" name="1" ><span class="b-ref">1</span>(2.4) Nevertheless, there is a shortage in<span> the </span>Rand Index, where the same equivalence is carried out among false negatives and false positives. Thereby, Rand (1971b) puts forward another method called<span> the </span>Adjusted Rand Index to solve this problem. Furthermore, F-measure ends this issue too. 2.3.3 F-measure F-measure, F score or F1 score, is often used in text classification area for evaluating the performance of different classifiers (Fujino et al., 2008). In this work, we will apply this algorithm to assess the performance of the relationship extraction pipeline. What is more, only the traditional F-measure will be taken into consideration. Here below equation is the formula of F-measure.<span> P </span>·R −1 + P−1 =2·P+R<span> . (2.5) </span>R Where the P is precision and the R means recall. What is more, the formulas of precision and recall are described as:</a> (2.6) <a href="javascript:openDSC(630550565, 2, '211');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="211" name="1" ><span class="b-ref">1</span>2.4 Summary In this chapter, all the tools, methodologies and algorithms involved in this work are acquainted. There are three steps, which has been mentioned at the start of this chapter. In the first step, PDFMiner, Apache<span> PDFBoxr </span>and OpenCV OCR with Tesseract are explained in detail, especially how it helps to extract text and coordinate. Then, in the second step, two methodologies: the Euclidean Metric and K-Means Clustering are introduced during the Relationship Extraction process. At last, three types of evaluation algorithms: Purity, Rand Index and F-measure are presented, helping assess the quality of our extraction pipeline. Chapter 3<span> Requirements and </span>Analysis In this chapter, three sub-tasks will be put into details, showing how we handle the process of relationship extraction under the project requirements. 3.1<span> Project </span>Requirements As it is mentioned before, the project requires us to build a system, which can automatically describe the status when asking any rooms in the Diamond building. More powerfully, it could tell you how these rooms are related. When the temperature<span> rises, </span>which happens only in one room but not all rooms, it can tell you where is the possible damaged root of the cooling system because it holds the relationship between rooms and rooms, rooms and sensors. However, such a colossal system can not be easily implemented. This work only focuses on the first step toward finding the relationship between rooms and sensors but not the whole system. Only if the system possesses these relationships, it can respond to any other types of problems. Thereby, in this work, we create a relationship extraction pipeline to tackle with this problem. Figure 3.1 shows how the data flow among these three steps. Figure 3.1: The Relationship Extraction Pipeline 14 CHAPTER 3.<span> REQUIREMENTS AND </span>ANALYSIS</a> 15 3.2 Project <a href="javascript:openDSC(630550565, 2, '222');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="222" name="1" ><span class="b-ref">1</span>Data It needs to be<span> emphasised </span>that all documents we use, which comes from the contractor’s drawings, are one particular type where the text is on floor plans. 3.3 Function Requirements The functional requirements are shown in Table 3.1 below. Function Sub-function ID Necessity Description PDFBox Extractor 1.1 Mandatory Extracting PDF file through Apache</a> PDFBoxr Text and coordinate <a href="javascript:openDSC(630550565, 2, '235');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="235" name="1" ><span class="b-ref">1</span>Extraction PDFMiner Extractor 1.2 Optional Extracting PDF file through PDFMiner OpenCV Extractor 1.3 Optional Extracting PDF file through OpenCV OCR with Tesseract Relationship Extraction Euclidean Distance 2.1 Mandatory Extracting relationship through Euclidean Distance K-Means Clustering 2.2 Optional Extracting relationship through K-Means Clustering Purity metric 3.1 Mandatory Using Purity metric to<span> evaluate </span>the performance<span> Evaluation </span>Rand Index metric 3.2 Optional Using the Rand Index<span> metric </span>to evaluate the<span> performance </span>F-measure metric 3.3 Optional Using the F-measure metric to evaluate the performance Table 3.1: The Function Requirements CHAPTER 3.<span> REQUIREMENTS AND </span>ANALYSIS<span> 16 3.4 </span>Function Improvement At the second step of the extraction pipeline, if we directly apply the Euclidean distance or K- Means clustering methodology, therefore, some information about the boundaries will be directly ignored. Since a room only has one corresponding text label to identify this room, if the room is too large, it will happen that a sensor, which is too far from the room text label, is judged to be associated with another room. To solve this problem, we shell use OpenCV to find the boundaries about the rooms so that the result of clustering can be better. 3.5 Ethical, Professional and Legal Issues This work does not require ethical review because the building drawings and sensor information, which used during this work, are proprietary and owned by the University. Although getting it is easy, there are ethical concerns and legal issues with me not sharing too much of it with anyone. What is more, some aspects of building data can be personal and confidential, where it showed named peoples’ offices for example. During the working period, data leaks or illegal operations never happens. All the data comes from the result of the experiments themselves without any artificial tampering. Moreover, it against nothing on BCS code of conduct or the legislation. Chapter 4 Planning 4.1 Risk Analysis Table 4.1 shows that to what extent do these risks affect the entire job, where the Risk Level from 1 to 3 represents low to high. ID Description Risk Level Action 1 Lacking experience on OpenCV tool; may cause the coding error. 3 Self-learning and communicate with supervisor regularly. 2 Boundaries extraction method may not work well; may cause ill result after the relationship extraction process. 2 Considering change other methods to extract the boundaries of rooms. 3 Lack of essay writing skills; may cause inappropriate writing style. 1 Attending the online writing courses provided by Department of<span> Computer </span>Science. 3<span> Realtime </span>performance shortfalls because different program languages may be involved. 1 Consider using the same program language in dealing with the work. Table 4.1: A List of Risks<span> 17 </span>CHAPTER 4. PLANNING</a> 18 4.2 Project <a href="javascript:openDSC(630550565, 2, '264');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="264" name="1" ><span class="b-ref">1</span>Breakdown Structure Figure 4.1 illustrates the project breakdown structure. Even if there are three sub-tasks, two of them can be classified as extraction operation. By exercising PDFminer, PDFbox or OpenCV OCR, the text and coordinate can be extracted from PDF files. After that, Euclidean Distance or K-Means Clustering is used in finding the relationship between text. At last, Purity, Rand Index and F-measure are carried out in the evaluation process. Figure 4.1: The Project Breakdown Structure<span> 19 </span>CHAPTER 4. PLANNING 4.3 Project Plan Table 4.2 shows that the main objectives with their dates of work. Objectives Start Finish Write Background Report</a> April 17, 2020 May 27, 2020 Text and Coordinate Extraction March 29, 2020 June 25, 2020 Relationship Extraction <a href="javascript:openDSC(665035235, 37, '22368');" onmouseover="doRollover(13);" onmouseout="undoRollover(13);" id="22368" name="13" ><span class="b-ref">13</span>June 26, 2020 July<span> 15, </span>2020<span> Evaluation </span>July 16, 2020 August<span> 10, </span>2020</a> Write a Dissertation Report May 29, 2020 August 31, <a href="javascript:openDSC(630550565, 2, '268');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="268" name="1" ><span class="b-ref">1</span>2020 Table 4.2: The Main Objectives and Dates There are more details about the project plan, which can be found in appendix A including the whole Gantt chart. Chapter 5</a> Implementation, Assembly, Test and Evaluation In this chapter, all methods mentioned above will be implemented. What is more, the most suitable method in each sub-task will be taken out to form the extraction pipeline. After that, the assembled extraction pipeline will take a test as well as three types of evaluation methods. 5.1 Implementation In this section, three sub-tasks will be implemented in different ways, respectively. 5.1.1 Text and Coordinates Extraction The first sub-task of the whole project is to extract the text and coordinates from building drawings. Before processing the drawings, there are two types of drawing should be introduced. One is a black and white drawing, where the text is on floor plans. The other is a colourful drawing, where the text mixes with other lines. Therefore, the drawing is a picture. Figure 5.1 and Figure 5.2 are two types of building drawings, which show the same room named E.06 BREAKOUT ROOM 3.7. Owing to the types of building drawings are not unique, some methods are only suitable for one of these types. Hence, I apply PDFMiner tool as well as PDFBox tool to the first monochrome type of building drawing and use OpenCV tool to the colourful one. In order to be consistent, only the file named 34676-M57-0302 Iss7.pdf will be shown in this work during the process of extraction. Character $ will be used to represent line breaks when representing the content of the text. 20 CHAPTER 5. IMPLEMENTATION, ASSEMBLY, TEST AND EVALUATION 21 Figure 5.1: A Sample of Monochrome Building Drawing Figure 5.2: A Sample of Colourful Building Drawing 5.1.1.1 PDFMiner Extractor Implementation To solve the first sub-task, I firstly used a tool named PDFMiner written in python language. It is a third-part open-source tool extracting information from PDF document. The code, which I used to extract text and coordinate, is based upon the tutorial example in the PDFMiner docs(https://pdfminersix.readthedocs.io/en/latest/tutorial/composable.html) and the example from Code Examples (https://code-examples.net/en/q/15d65e1). Extraction Result of the PDFMiner Extractor ------------------------------------------------------------ ID, X-axis, Y-axis, Text 78, 641, 1440, SD.2901 79, 645, 1176, (CB-06) 80, 670, 1341, BREAKOUTROOM3.8 81, 670, 1224, (cid:145) (cid:19) (cid:19) (cid:21) 82, 675, 2105, 1150x500 83, 684, 1683, SD.2901 84, 699, 1256, 1 9 E T T A 1 2 3 4 5 6 7 8 85, 699, 86, 701, ------------------------------------------------------------ 1281, . 1311, V C D 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 A Sample of Extraction Result by PDFMiner The above part is a sample result of extraction by PDFMiner tool. Where ID means the number of discovered text, X-axis means x-axis coordinate, Y-axis means y-axis coordinate and Text means the text of the corresponding x-axis and y-axis coordinates. It should be emphasised that coordinate (0, 0) locates on the bottom-left of building drawings. Therefore, the value of y-axis goes up when a point moves from bottom to top on the building drawings. Similarly, the value of x-axis increases when a point shifts from left to right. The above result, which is extracted by PDFMiner, shows that most of the text can be extracted correctly. Notably, the vertical text also can be extracted according to the visual order from top to bottom. However, the extraction effect of PDFMiner is not good. There are four main shortages from the above result. Firstly, it shows that the text ’SD.2901’ appears in coordinate (641, 1440) and ID is 78. Nevertheless, Figure 5.3 indicates that the actual text in the red rectangle area is ’S/D.29/01’. As a result, forward slashes always are ignored by this tool. Figure 5.3: The Actual Text: ’S/D.29/01’ Secondly, it shows that the text ’BREAKOUTROOM3.8’ turns up in coordinate (670, 1341) with ID is 80, but Figure 5.4 shows the actual text in the red rectangle area is ’BREAKOUT ROOM 3.8’. It means the spaces are removed by this tool, and the words thereby cannot be identified. Besides, the blue and red rectangle areas should be an entirety, so all text in these areas are better to be extracted at the same time. Thirdly, it shows that the text ’(cid:145)$(cid:19)$(cid:19)$(cid:21)’ comes out in coordinate (670, 1224) with ID is 81, yet Figure 5.5 demonstrates the actual text in the red rectangle area is ’200∅’. After some investigation, it is clear that PDFMiner writes strings like ’(cid:...)’ when it is not able to recognise the letter font or encoding. Fortunately, Figure 5.4: The Actual Text: ’BREAKOUT ROOM 3.8’ only some special characters, which are not targeted text, fail to be recognised. Figure 5.5: The Actual Text: ’200∅’ Fourthly, it shows that the text ’1$9$E$T$$T$A’ presents in coordinate (699, 1256) with ID is 84, however Figure 5.6 indicates the actual text in the red rectangle area is ’ATT/E.39/1’. The orientation, which is ignored by this tool, is the problem here. There are three directions in Figure 5.6: Direction from left to right; Direction from top to bottom; Direction from bottom to top. According to the result sets, the tool neglects the direction from bottom to top so that the extracted text looks upside down. Besides, there is a small problem that the extracted text may do not appear in building drawings. As I look through the whole result sets, only some meaningless dots are identified, so it has almost no effect on our task. 1 2 3 4 5 6 7 8 Figure 5.6: The Actual Text: ’ATT/E.39/1’ Conclusion of the PDFMiner Extractor Anyhow, PDFMiner is a useful tool in terms of extracting information from PDF file, although it is not appropriately suitable for our task. This sub-task requires the text and coordinate of rooms and sensors should be correctly and orderly extracted. It means that the missing text and the wrong order can not be tolerated, therefore the first, second and fourth shortages are not acceptable so that the PDFMiner Extractor needs to be given up from handling this sub-task. 5.1.1.2 PDFBox Extractor Implementation The next tool, which is named PDFBox wrote in Java language, is used to extracting text with its coordinate from the monochrome PDF document. The code, which I used to extract text and coordinate, is based upon the example codes of the Apache PDFBox(https://github.com/apache/pdfbox/blob/trunk/examples/src/main/java/org/apac he/pdfbox/examples/util/PrintTextLocations.java) in GitHub. Extraction Result of the PDFBox Extractor -------------------------------------------------------------- ID, X-axis, Y-axis, 58, 489.58, 59, 504.75, 60, 532.86, 940.76, 884.72, 1009.6, Text E/D.29 VCD BREAKOUT ROOM 3.7 61, 533.06, 977, E.06 62, 534.25, 1069.8, 8 Seats 68, 610.72, 1104.2, ATT/E.39/2 63, 560.43, 763.76, VCD 64, 581.32, 232.32, 800 65, 589.99, 1205, E/E.39 66, 605.08, 1055.7, VCD 67, 609.40, 193.68, 100 69, 644.22, 789.20, VAV/D.29/01 70, 660.46, 941.84, S/D.29/01 (CB-06) 71, 661.34, 1205, -------------------------------------------------------------- 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 A Sample of Extraction Result by Apache PDFBox The above part is a sample result of extraction by PDFBox tool. It should be noted that that coordinate (0, 0) locates on the top-left of building drawings, which is different from the previous PDFMiner tool. Thus, The horizontal coordinate will increase from left to right. Correspondingly, the vertical coordinate is going to increase from top to bottom. There are also some shortfalls, but PDFBox looks much better comparing to the PDFMiner. First of all, it correctly extracts text with space. For example, when ID is 60 and the coordinate is (532.86, 1009.6), the text is ’BREAKOUT ROOM 3.7’. Next, the forward slashes are perfectly spotted as well, such as the text is ’ATT/E.39/2’, when the coordinate is (610.72, 1104.2) and Id is 68. Owing to the supporting of an arbitrary angle of text rotation provided by PDFBox, it is undoubted that any direction of text can be found rightly. In addition, PDFBox can extract more accurate coordinates than PDFMiner. Notwithstanding PDFBox can make up for some shortcomings coming from PDFMiner, others are still problems. PDFBox also holds the same problem as PDFMiner, where not all types of fonts and encodings can be recognised. It is various from PDFMiner that the unrecognised text will not be displayed but simply discarded. So as to be able to detect this problem, we need to observe the output warning messages while running the PDFBox detector codes. Figure 5.7: The Warning Messages of Unknown Font or Encoding Figure 5.7 shows that some text has no Unicode mapping in font ArialMT so that these texts can not be extracted. After investigation, I found that the problem did not affect our task because all texts related rooms and sensors already exist. Only a small part, such as room size and the unit of area (m2), are ignored. Besides, if you focus on three IDs(60, 61, 62), it obvious that these three parts of the text should be considered as a whole to describe a room. Also, the order of these three IDs needs to be adjusted to meet the actual situation, thereby the correct order should be 61, 60 and 62. Figure 5.8 shows the actual text. Figure 5.8: The Actual Text: ’E.06 BREAKOUT ROOM 3.7 14.63 m2 8 Seats’ Conclusion of the PDFBox Extractor According to the extraction results, PDFBox is suitable for this sub-task when applying to monochrome PDF files. All useful and related texts are correctly extracted without error. However, only one problem has already been mentioned that some texts about room names are in an incorrect order, thus some steps need to be taken during the extraction process to ensure order. 5.1.1.3 OpenCV Extractor Implementation The following tool, which is used to recognise text from colourful PDF files, is different from the previous two. The colourful PDF files, which is used in our project, contain text where not on floor plans, as I mentioned before. So as to handing this type of text recognition, I use OCR with Pytesseract and OpenCV. Installation It is quite easy to install OpenCV, Tesseract and pytesseract4 on Ubuntu with below commands. In addition, Anaconda is required to be installed before you use these commands. $ <a href="javascript:openDSC(2495171715, 3788, '26166');" onmouseover="doRollover(21);" onmouseout="undoRollover(21);" id="26166" name="21" ><span class="b-ref">21</span>sudo apt install python3-opencv $ sudo apt install</a> tesseract-ocr libtesseract-dev $ conda install -c conda-forge poppler pytesseract 4 The python wrapper for tesseract. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Extraction Code The code in Listing 5.1 contains the whole extraction process, where the code is based on the tutorial example on the Nanonets website(https://nanonets.com/blog/ocr-with- tesseract/#installingtesseract). The PDF file is converted to JPEG file first, and then Tesseract will try to find all texts in the JPEG file. Finally, all the texts will be highlighted with green rectangles. import cv2 <a href="javascript:openDSC(1082743014, 2474, '27522');" onmouseover="doRollover(23);" onmouseout="undoRollover(23);" id="27522" name="23" ><span class="b-ref">23</span>import pytesseract from PIL import Image from<span> pdf2image </span>import</a> convert_from_path # reset maximum image pixels (34676-M57-0302_Iss7.pdf:387460068) Image.MAX_IMAGE_PIXELS = 1000000000 # file name MONOCHROME_FILE = ’34676-M57-0302_Iss7’ COLOURFUL_FILE = ’AMG-34676-M57-0302_Iss2’ FILE_NAME = COLOURFUL_FILE # convert pdf to jpeg pages = convert_from_path(FILE_NAME + ’.pdf’, 500) for page in pages: page.save(FILE_NAME + ’.jpg’, ’JPEG’) # read picture file img = cv2.imread(FILE_NAME + ’.jpg’) 15 16 17 18 19 20 21 22 h, w, c = img.shape # mark the text in the picture <a href="javascript:openDSC(1117620949, 3791, '23066');" onmouseover="doRollover(6);" onmouseout="undoRollover(6);" id="23066" name="6" ><span class="b-ref">6</span>boxes = pytesseract.image_to_boxes(img) for b in boxes.splitlines(): b = b.split(’ ’) img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), \ (int(b[3]), h - int(b[4])), (0, 255, 0), 2)</a> # write picture to file cv2.imwrite(FILE_NAME + ’_with_boxes.jpg’, img) # show the picture # cv2.imshow(FILE_NAME + ’_with_boxes’, img) 23 24 25 26 27 28 29 30 31 32 33 34 35 Listing 5.1: Extraction Code Using OpenCV with Tesseract Extraction Result of the PDFMiner Extractor Figure 5.9 illustrates a part of the extraction results, which is extracted through OpenCV and Tesseract. All green boxes in Figure 5.9 represent a character or a group of characters. Sadly, the results show that OpenCV and Tesseract are not suitable for the current task, where the PDF file contains so many details that make OpenCV and Tesseract over capture text. What is worse, this combination tool can not provide coordinate of text. In my entire project structure, I need to cluster the text by coordinates. Without text with its corresponding coordinate, the work can not be finished. Besides, there are some issues when recognising text. To begin with, texts enclosed by the red rectangle in Figure 5.9 show that not all characters in PDF file are correctly extracted, hence some related information will lose. Not only the text related to the room could not be fully extracted, but also the text referred to the sensor can not be extracted entirely. Therefore, it is impossible to identify room and sensor through these texts. Next, there are so many false detections. If you put your attention on the text enclosed by the sky-blue rectangle in Figure 5.9, the unknown content in the number 0 is detected. Then, the recognised results enclosed by the yellow rectangle in Figure 5.9 are not text from a visual point of view. Last but not least, Figure 5.10 shows that the text enclosed by the sky-blue rectangle is impossibly recognisable. Because this type of PDF file contains text, which is not on floor plans and some texts are covered by the line of a wall or facility. Moreover, There are a lot of green lines in the right half of Figure 5.10, which looks messy. Figure 5.9: A Part of Extraction Result by OpenCV and Tesseract Figure 5.10: The Unrecognisable Covered Text Conclusion of the OpenCV and Tesseract Extractor It is quite obvious that this join tool is not suitable for this sub-task as the result indicates this tool will mix up all texts. Particularly, it extracts texts without its corresponding coordinate. Thus, the next task can not be carried out. Comparing to PDFMiner and PDFBox, OpenCV and Tesseract have more shortages than them. 5.1.2 Relationship Extraction The second sub-task of the whole project is relationship extraction, which requires a clustering process to assign all sensors to its corresponding room after the text and coordinate of room and sensor are correctly extracted. In this section, all work is based upon the results of the previous sub-task, which means there are no PDF files anymore. The more reliable the results got from previous sub-task, the more accurate the results obtained from the clustering process. 5.1.2.1 Euclidean Distance Implementation The first idea that comes to my mind is to calculate the distance between rooms and sensors, where the simplest distance algorithm should be the Euclidean distance. Associate the sensor with the room closest to it until all sensors are assigned to a room. Extraction Code The code in Listing 5.2 shows the core function code to extraction relationship between rooms and sensors, where it contains a parameter that is a type of distance calculation function. 1 2 3 4 5 6 7 8 9 10 11 By default, the function is the Euclidean distance function, where the code in Listing 5.3 indicates its implementation. Additionally, the function can be replaced by other types of distance function, such as Manhattan distance, Minkowski distance and Chebyshev distance. Amongst the process of relationship extraction, all the sensors information iterate first, and then distance function will be applied to calculating the distance between the sensor and all rooms. After that, the number of the room for the shortest distance will be set as the group ID of the sensor. /** * Assign all sensors to its closest room. * * @param func A Distance Calculation Function */ public void extractRelation(BiFunction&lt; CoordinateText.Coordinate, CoordinateText.Coordinate, Float&gt; func) { // check label if (!canExtract) { return; } // iterate all sensors coordinateSensorsTexts.forEach(coordinateSensorText -&gt; { List&lt;Float&gt; distances = Lists.newArrayList(); coordinateRoomsTexts.forEach(coordinateRoomText -&gt; { // calculate and store distance distances.add(func.apply( coordinateSensorText.getMiddle(), coordinateRoomText.getMiddle())); }); // find minimum distance Float minDis = Collections.min(distances); int groupId = distances.indexOf(minDis); // set groupId coordinateSensorText.setGroupId(groupId); }); } 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 Listing 5.2: Relationship Extraction Code by Calculating Distance // A Function of Calculating Euclidean Distance public static BiFunction&lt;CoordinateText.Coordinate, CoordinateText.Coordinate, Float&gt; EUCLIDEAN_FUNC = (a, b) -&gt; (float) <a href="javascript:openDSC(350913196, 1, '21127');" onmouseover="doRollover(8);" onmouseout="undoRollover(8);" id="21127" name="8" ><span class="b-ref">8</span>Math.sqrt( Math.pow(b.getX() - a.getX(), 2) + Math.pow(b.getY() - a.getY(), 2)</a> ); 1 2 3 4 5 6 7 Listing 5.3: A Function of Calculating Euclidean Distance Relationship Extraction Result by Euclidean Distance The below part is a sample result of relationship extraction through calculating the euclidean distance between sensors and rooms to determinate the group. Firstly, there are two types of Type which are ROOM and SENSOR respectively. Then, the id of groups are random, but the id is the same when some sensors are close to the same room. It is clear from the results that some texts are the same but different in position. However, it is not the fault of the previous text and coordinate extractor because the PDF file cannot provide more details about the same text. Therefore, it can be ignored here. Besides, the results show that two ATT/E.39/2 are identified as group 3. Nonetheless, Figure 5.11 indicates only four texts of sensors, which are enclosed by the red rectangles, are belonging to E.06 BREAKOUT ROOM 3.7. Texts in blue rectangles are false detection. It is quite easy to understand that these selected texts are closer to E.06 BREAKOUT ROOM 3.7 but not other rooms. So how to reduce this false positive can be another problem waiting to be solved. I will introduce how to deal with this problem in a later section. 1 2 3 4 5 6 ---------------------------------------------------------------- X-axis, Y-axis, Text, Type, 532.86, 1023.44, E.06 ROOM, BREAKOUT ROOM 3.7 8 Seats 390.64, 1092.1, ATT/E.38/1, SENSOR, 456.28, 1090.8, ATT/E.38/2, SENSOR, 610.72, 1104.2, ATT/E.39/2, SENSOR, 489.58, 672.68, E/D.29, SENSOR, 703.90, 698.48, S/D.29/01, SENSOR, 644.22, 789.20, VAV/D.29/01, SENSOR, 489.58, 940.76, E/D.29, SENSOR, 660.46, 941.84, S/D.29/01, SENSOR, 589.99, 1205, E/E.39, SENSOR, 810.42, 1050.91, E.07 ROOM, BREAKOUT ROOM 3.8 6 Seats 710.43, 1105.57, ATT/E.39/1, SENSOR, ---------------------------------------------------------------- 798.52, 1095.85, ATT/E.40/2, SENSOR, Group 3 3 3 3 3 3 3 3 3 3 4 4 4 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 A Sample of Relationship Extraction Result by Euclidean Distance Conclusion of the Euclidean Distance It is quite convenient to use Euclidean distance to calculate the distance between the sensor and the room for grouping. Even though this method shows its talent in clustering, it is not perfect because the results contain some false positive. There is still work to be done to improve accuracy. Figure 5.11: The Relationship Extraction Result of E.06 5.1.2.2 K-Means Clustering Implementation In the previous section, the operation of grouping by calculating Euclidean distance is introduced. Consider that this sub-task is a clustering process, thus K-Means Clustering method can be useful. Implementation by Calling Scikit-Learn Library The code in Listing 5.4 shows the core code in the clustering process. It first creates a K- Means object by Scikit-learn library and then trains the model with coordinates. After that, it predicts the result label for each coordinate. # construct a K-Means object kmeans = KMeans(num_classes, random_state=random_seed, max_iter=50, algorithm=’full’) 1 2 3 # train and predict clustering result clusters = kmeans.fit_predict(features) 4 5 Listing 5.4: Extraction Code Using OpenCV with Tesseract The previous code in Listing 5.4 indicates that the relationship extraction process is easy to be implemented through Scikit-learn library. However, if you have a look at the result from below, a problem occurs, where two rooms are in the same group. During the initial process of KMeans object, the number of K can be manually set to the number of room, which is identified in the previous task. But I do not set the initial centre points, therefore random initial centre points may cause this. To solve this problem, centre points are added to the K-Means object. All room coordinates, which are identified in the previous extraction process, are set as the initial centres of K-Means clustering process. 1 2 3 4 5 6 7 8 9 10 11 12 13 ---------------------------------------------------------------- ID, X-axis, Y-axis, Text, 44, 1321.0, 629.84, E.27 ICT ROOM 45, 1453.1, 764.18, E.28 FEMALE TOILETS 46, 1532.9, 748.21, ATT/E.44/1 48, 1461.7, 628.28, E/E.44 51, 1461.7, 729.68, E/E.44 ---------------------------------------------------------------- Type, Group ROOM ROOM SENSOR 0 0 0 SENSOR 0 SENSOR 0 14 15 A Sample of Relationship Extraction Result by Scikit-learn K-Means Clustering(1) Although the impact of the problem has diminished by setting initial centres, the below results point that it still exists. When group id equals to 6, two sensors in a group but not belongs to any room. When group id equals to 7, three rooms are still classified in the same group. Figure 5.12 reveals that there are three rooms close to each other without any other sensors. Thus, the three-room are easily classified in the same group by this type of unsupervised learning algorithm. ---------------------------------------------------------------- ID, X-axis, Y-axis, Text, Type, Group 41, 908.90, 1205, (CB-05), SENSOR, 6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 42, 1086.2, 1369.7, TG/E.34, 43, 1095.9, 960.56, E.33 STAIR 2, 44, 1106.4, 1090.7, E.31 LIFT, 45, 1301.6, 1090.4, E.32 CORE 2, ---------------------------------------------------------------- SENSOR, 6 ROOM, 7 ROOM, 7 ROOM, 7 16 A Sample of Relationship Extraction Result by Scikit-learn K-Means Clustering(2) Figure 5.12: E.31 - E.32 - E.33 Conclusion of the K-Means Clustering <a href="javascript:openDSC(563206686, 3722, '24227');" onmouseover="doRollover(14);" onmouseout="undoRollover(14);" id="24227" name="14" ><span class="b-ref">14</span>K-Means Clustering is similar to the<span> former </span>method,<span> where </span>it</a> can use Euclidean distance <a href="javascript:openDSC(3143643921, 3783, '26490');" onmouseover="doRollover(17);" onmouseout="undoRollover(17);" id="26490" name="17" ><span class="b-ref">17</span>to calculate the distance between<span> each </span>data points.<span> Even though </span>the<span> K value and </span>the</a> initial centre points are set before clustering, it still makes more significant mistake than the Euclidean distance method. Because it does not divide up every room, but the sub-task requires each room holds a different group id. 5.1.2.3 Auxiliary Relationship Extraction The above two methods solve the problem of relationship extraction to some extent, but these methods only consider the coordinate distribution but not the actual circumstance. The room has a specific size and scope, where only sensors in or close to the range of the room should be taken into account. Therefore, the room range can be used as additional information for relationship extraction. In this section, the room range extraction technology will be introduced here as an auxiliary for relationship extraction. Actually, the whole room range extraction also is an extraction pipeline, but it will not be taken into details. The Room Range Extraction Pipeline In this pipeline, most operations are done by calling the OpenCV library, and especially, the last step uses the cv2.findContours() method to find contours of rooms. Before that, it will be a series of pre-processing. The following will be the five main steps of the room range extraction pipeline. More details about the last step will be introduced later. (s1) Remove text from PDF file. (s2) Convert PDF file to PNG image file. (s3) Remove room doors. (s4) Dilate image to reduce noise. (s5) Erode image to enhance details. (s6) Find contours of rooms. The first four steps are called pre-processing. Firstly, I will still use PDFBox with its provide example code to remove all texts on floor plans to make PDF file more clear, which helps to eliminate most noise. The next step is to convert PDF file to PNG image file because the following step requires OpenCV library, where it can accept the image but not a PDF file. Then, the doors of rooms in the image need to be removed, however, it still is a problem to be solved for me so that this step will be ignored during pre-processing. After that, the dilation and erosion process will be taken to reduce noise and improve image quality with the help of OpenCV. Finally, use OpenCV to get the outlines of all the rooms. More precisely, the following steps are needed to extract the outline of the house. • Remove noise left from door removal. It contains a parameter, which controls the minimal area of blobs to be kept. When the area is less than the threshold, it will be regarded as noise, and then, can be ignored directly. • Detect corners. It contains a parameter, which controls the numbers of detected corners. The bigger the value of this parameter is, the more the room will be removed. • Draw lines to close the rooms. It contains a parameter that indicates the maximum line length to add to close off open doors. It needs to be emphasised that Drawing a line through other existing lines should be avoided. • Mark the outside of the house. The areas outside of the house should be ignored. • Find the connected components. The connected components should be treated as rooms. Conclusion of the Room Range Extraction Pipeline When I feed a simple picture of this pipeline, it shows a great achievement. Figure 5.13 is the result after a series of pre-processing, where holds no doors and big noise blocks. After passing it to the room range extraction pipeline, Figure 5.14 shows the result of room segmentation, where all rooms are filled with different colours. Figure 5.13: A Example of Building Drawing Picture Figure 5.14: The Result of Building Drawing By Taking Room Range Extraction Pipeline Figure 5.15: A Terrible Result of Room Extraction Figure 5.16: A Range of Room: E.28 FEMALE TOILETS Comparing Figure 5.13 with Figure 5.14, most of the rooms are correctly split and marked with colour in addition to the corridors. Although it seems that this pipeline works well, when I put the actual building drawings into this pipeline, it looks terrible. As you can see from Figure 5.15, there is a black area on the right bottom side of the picture. Except for that, the blue area indicates the boundary. Why the result looks like nothing, if we go back to the actual building drawing, the problem may be reasonable. Figure 5.16 indicates room E.28 FEMALE TOILETS, where the red square shows its boundary. It is apparent that the walls are not clear or the lines are not thick enough. Besides, there are pipes inside of the room with a darker colour so that it much more obvious than what the wall shows. More importantly, there are too many details inside the room, thus make the room range extraction pipeline hard to do the split job. Consequently, it is quite difficult to use the room extraction pipeline to divide rooms with complex building drawings. 5.2 Test In this section, it is about how to identify whether the result, which is extracted from the relation extraction pipeline, is correct or wrong. Only how I define the accuracy will be introduced. 5.2.1 Benchmark and Result First of all, Table 5.1 gives a part of the benchmark result of PDF file 34676-M57-0302-lss7. It has three columns, containing text, type and group. type contains only two types, which are ROOM and SENSOR respectively. What is more, group is a random value, where the same value indicates the same group. Then, Table 5.2 gives a part of relationship extraction result of PDF file 34676-M57-0302lss7. It contains five columns, including x, y, text, type and group. x and y are the coordinates of its corresponding text. Apart from that, the rest columns are the same as the columns of Table 5.1. In order to compare the benchmark and the result, which is extracted by the relationship extraction pipeline, the ROOM type needs to be focused. It firstly selects all rows, which the group ID is the same as the one where the type is ROOM. Then, if the row in result also in the benchmark, the row will be regarded as correct. Furthermore, if the row in the result but not in the benchmark, it will be ignored. 5.2.2 The Accuracy Formula To make the calculation simple, the accuracy formula is defined by Equation 5.1: where CC means the number of rows, which is correctly classified. number of data rows. (5.1) ADP means the text type group BREAKOUT ROOM 3.5 ROOM 0 SILENT STUDY SPACE 1 30 Workplaces ROOM 1 SUF-03 SENSOR 1 E/E.26 SENSOR 1 FCU/E/02 SENSOR 1 4 No. S/E.26/3 SENSOR 1 Table 5.1: A Benchmark Result of File 34676-M57-0302-lss7 5.3 Evaluation In the previous section, the accuracy is simply defined to assess to what extent the pipeline can correctly extract. However, the accuracy works badly when the data sample is unbalanced. Therefore, in this section, three evaluation methods, which are Purity, Rand Index and F- measure, respectively, will be introduced to evaluate the relationship extraction pipeline performance. These methods have already been introduced before so that the following subsections will mainly engage in the implementation. 5.3.1 Purity Method Implementation In this section, the implementation of purity is introduced. Even though the definition or the formula is different from accuracy metric, they are actually the same after taking into implementation. For each classified cluster, select the max purity value and then treat it as the purity of its cluster. Finally, put all clusters’ purity value together to calculate the purity of the whole relationship extraction pipeline. 5.3.1.1 Purity Code The code in Listing 5.5 indicates the function of purity implemented by Java. Where resultCoordinateTexts is an instance of class CoordinateText, which contains a text, the coordinates of the text, the type of the text, and the group ID of the text. x y text type group - 12.652222 991.52 BREAKOUT ROOM 3.5 ROOM 0 149.38501 672.68005 E/D.29 SENSOR 0 -9.466431 1751.54 SILENT STUDY SPACE 1 30 Workplaces ROOM 1 215.83435 1630.88 E/E.26 SENSOR 1 107.13391 1736.48 SUF-03 SENSOR 1 229.2633 1781.6001 FCU/E/02 SENSOR 1 435.86438 1798.16 4 No. S/E.26/3 SENSOR 1 28.776611 2355.8 6No. S/E.12/2 SENSOR 1 Table 5.2: A Room Extraction Result of File 34676-M57-0302-lss7 /** * Calculate the Purity value * of relationship extraction pipeline * * @return The value of Purity */ public double getPurity() { AtomicReference&lt;Double&gt; allPurity = new AtomicReference&lt;&gt;(0.0); resultCoordinateTexts .stream() .collect( Collectors.groupingBy(CoordinateText::getGroupId) ).forEach((k, vs) -&gt; { int matchNum = 0; int benchmarkGroupId = -1; for (CoordinateText v : vs) { String name = v.toString(); // obtain the groupId in benchmark set if (v.getType() == Type.ROOM) { benchmarkGroupId 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 = benchmarkCoordinateTexts.stream() .filter( coordinateText -&gt; coordinateText.toString() .equals(name) ).findFirst() .get() .getGroupId(); continue; } int finalBenchmarkGroupId = benchmarkGroupId; boolean anyMatch = benchmarkCoordinateTexts .stream() // same groupId &amp;&amp; same text .anyMatch( coordinateText -&gt; coordinateText.getGroupId() == finalBenchmarkGroupId &amp;&amp; coordinateText.toString() .equals(name) ); if (anyMatch) { ++matchNum; } } double tmpPurity = matchNum * 1.0 / resultCoordinateTexts.size(); allPurity.set(allPurity.get() + tmpPurity); }); return allPurity.get(); } 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 Listing 5.5: A Function of Calculating Purity 5.3.2 Rand Index Method Implementation The next evaluation method is the Rand Index, where it compares the benchmark result with the extracted results to measure the similarity of them. <a href="javascript:openDSC(1086736713, 3791, '25161');" onmouseover="doRollover(19);" onmouseout="undoRollover(19);" id="25161" name="19" ><span class="b-ref">19</span>By counting the number of the appeared<span> same status </span>to</a> obtain the value of Rand Index. Equivalently, the implementation is still our focus. 5.3.2.1 Rand Index Code The code in Listing 5.6 shows the function of the Rand Index implemented by Java. This function is easy to be implemented because the formula itself is simple. However, it is not easy to control the result texts, which are extracted from PDF file, so that some useless texts may also be extracted. Thus, some texts, which come from the extracted result but do not appear in the benchmark result set, should be ignored. Ideally, both the extracted result set and the benchmark set should hold the same number of rows. Actually, <a href="javascript:openDSC(2955093730, 3788, '26204');" onmouseover="doRollover(22);" onmouseout="undoRollover(22);" id="26204" name="22" ><span class="b-ref">22</span>in a real-<span> world scenario, </span>make sure that the number</a> of the benchmark result set is <a href="javascript:openDSC(457652666, 2909, '24385');" onmouseover="doRollover(15);" onmouseout="undoRollover(15);" id="24385" name="15" ><span class="b-ref">15</span>greater than or equal to the number of the</a> extracted result set. 1 2 /** * Calculate the Rand Index value of * relationship extraction pipeline. * * @return The value of RandIndex */ public double getRandIndex() { assert benchmarkCoordinateTexts.size() &gt;= resultCoordinateTexts.size(); int sames = 0; int coordinateSize = benchmarkCoordinateTexts.size(); // Iteration <a href="javascript:openDSC(880251596, 3788, '24113');" onmouseover="doRollover(9);" onmouseout="undoRollover(9);" id="24113" name="9" ><span class="b-ref">9</span>for (int i = 0; i<span>&lt;</span><span> coordinateSize - </span>1; ++i) { for (int j = i + 1; j<span>&lt;</span><span> coordinateSize; </span>++j)</a> { boolean xStatus = getStatus( resultCoordinateTexts.get(i), resultCoordinateTexts.get(j)); boolean yStatus = getStatus( benchmarkCoordinateTexts.get(i), benchmarkCoordinateTexts.get(j)); sames += (xStatus == yStatus) ? 1 : 0; } } // Rand Index Formula 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 return sames * 2.0 / (coordinateSize * (coordinateSize - 1)); } /** * Judge if id of group are the same or not. * * @param x instance of CoordinateText object * @param y instance of CoordinateText object * @return if id of groups are the same return {@code True}, * otherwise, return {@code False} */ public boolean getStatus(CoordinateText x, CoordinateText y) { return x.getGroupId() == y.getGroupId(); } 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 Listing 5.6: A Function of Calculating Rand Index 5.3.3 F-measure Method Implementation The last assessment method is the F-measure method. It is a little bit sophisticated than previous two ways. Firstly, each cluster in the extracted result set should calculate its F- measure value, and then put them together with its weight to calculate the ultimate F-measure 1 2 3 4 5 6 value. During the calculation of each clusters’ F-measure value, each cluster in extracted result set should do the same calculation process with all clusters in the benchmark result set, where the max F-measure value will be regarded as the F-measure of the specific cluster in the extracted result. 5.3.3.1 F-measure Code The code in Listing 5.7 gives the function of F-measure method implemented by Java. This function requires the calculation of precision and recall value each cluster in the extracted result set so that it spends much more time in calculation than the previous two methods. /** * Calculate the F-measure value * of relationship extraction pipeline * * @return The value of F-measure */ public double getFMeasure() { double fMeasure = 0.0; int m = (int) benchmarkCoordinateTexts.stream() .map(CoordinateText::getGroupId) .distinct() .count(); int n = resultCoordinateTexts <a href="javascript:openDSC(3814833410, 3722, '26979');" onmouseover="doRollover(18);" onmouseout="undoRollover(18);" id="26979" name="18" ><span class="b-ref">18</span>.size(); for (int j = 0; j &lt; m; ++j) { int</a> finalJ = j; // find each group in benchmark set List&lt;CoordinateText&gt; bCoordinateTexts = benchmarkCoordinateTexts.stream() .filter( coordinateText -&gt; coordinateText .getGroupId() == finalJ ).collect(Collectors.toList()); long pJ = bCoordinateTexts.size(); // find ROOM in each benchmark group CoordinateText roomCoordinateText = bCoordinateTexts.stream() .filter( coordinateText -&gt; coordinateText .getType() == Type.ROOM ).findFirst() .get(); // find group id in result set int rGroupId = resultCoordinateTexts.stream() .filter( coordinateText -&gt; coordinateText.toString() .equals(roomCoordinateText.toString()) ).findFirst() .get() .getGroupId(); // find the same group in result set List&lt;CoordinateText&gt; rCoordinateTexts 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 = resultCoordinateTexts.stream() .filter( coordinateText -&gt; coordinateText .getGroupId() == rGroupId ).collect(Collectors.toList()); int cI = rCoordinateTexts.size(); // compare and calculate F-measure_j long pjci = rCoordinateTexts.stream() .filter( rCoordinateText -&gt; bCoordinateTexts.stream() .anyMatch( bCoordinateText -&gt; bCoordinateText .toString() .equals( rCoordinateText.toString() ) ) ).count(); // precision &amp;&amp; recall double precision = pjci * 1.0 / cI; double recall = pjci * 1.0 / pJ; // F-measure double tmpFMeasure = 2 * precision * recall / (precision + recall); // weight double wJ = pJ * 1.0 / n; // accumulative F-measure fMeasure += tmpFMeasure * wJ; } return fMeasure; } 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 Listing 5.7: A Function of Calculating F-measure 5.3.4 Evaluation Methods Results +------------------------------------------------------------+ | Extraction Result | +----------------------+-------------------------------------+ | Extracted PDF File: | 34676-M57-0302_Iss7.pdf | +----------------------+------------+------------+-----------+ | Accuracy | Purity | Rand Index | F-measure | +----------------------+------------+------------+-----------+ | 63.77% | 0.6377 | 0.9165 | 0.8430 | +----------------------+------------+------------+-----------+ 1 2 3 4 5 6 7 8 9 The Results of Evaluation methods The above <a href="javascript:openDSC(627976771, 37, '21378');" onmouseover="doRollover(24);" onmouseout="undoRollover(24);" id="21378" name="24" ><span class="b-ref">24</span>shows the results of the<span> evaluation methods. The </span>Accuracy and<span> Purity </span>the</a> same, where it has been told before. The Rand Index and F-measure give a much higher rating of this relationship extraction pipeline than Accuracy and Purity. 5.4 Relationship Extraction Pipeline Assembly Figure 5.17: Relationship Extraction Pipeline Structure There are three text extraction methods, two relationship extraction methods, one auxiliary method, as well as three evaluation methods, have been introduced in the earlier section. In this section, to assemble a complete extraction pipeline, which also includes evaluation, it requires to choose the best text extraction and the most suitable relationship extraction method. 5.4.1 Relationship Extraction Pipeline Structure Figure 5.17 indicates the final relationship extraction pipeline. It starts with a PDF file as its input. And then, it turns out two ways, where one is text and coordinate extractor, and the other is optional. On the extractor side, the PDFBox, which almost meets my needs, is my ultimate choice. On the other side, it is an auxiliary method that can extract the range of each room, therefore, it could be a position limitation when clustering the texts. Next, the PDFBox Extractor is followed by the Euclidean Distance Extractor. K-Means Clustering Extractor is given up because it can not divide each room into a single group, where it makes the evaluation impossible. Meanwhile, if the room range information is provided by the OpenCV Room Divider, it will be mixed into the process of relationship extraction to make the extraction result more 1 2 3 4 5 6 7 8 9 precise. Eventually, the final extracted results will be put into three different evaluation methods to identify the extent of its performance. 5.4.2 Linking Between Extractors Before the text and coordinate results are sent to the next extractor, two steps need to be taken. • Merge room text • Remove useless text The first step is to solve a problem, which has already mention in previous sub-section 5.1.1.2. Figure 5.8 indicates a situation that some text should be merged together so as to describe a specific room. Not only the PDFBox but also the PDFMiner has this problem. The below is a sample that needs to be combined together. -------------------------------------------------------------- ID, X-axis, Y-axis, 60, 532.86, 1009.6, 61, 533.06, 977, 62, 534.25, 1069.8, -------------------------------------------------------------- Text BREAKOUT ROOM 3.7 E.06 8 Seats To solve this problem, two parameters, which are tolerance x and tolerance y individually, are introduced. When the coordinates of the text are not too far apart, it is considered a description of the same room. More specifically, when the difference between the abscissa is less than or equal to the tolerance x and the difference between the ordinates is less than or equal to the tolerance y, these texts should be merged together. By default, tolerance x is 10 and tolerance y is 100. Besides, the merged text should obey the visual order, hence these texts will be sorted by y-axis value. Lastly, the connected text replace CRLF 5 with a slash in order to facilitate storage and display. What is more, the coordinate of text also should change, where it simply use the mean-value coordinate of them. In the end, the result of the above sample will be shown as below. -------------------------------------------------------------- ID, X-axis, Y-axis, Text 61, -------------------------------------------------------------- 533.39, 1018.8, E.06_BREAKOUT ROOM 3.7_8 Seats 1 2 3 4 5 The second step is to remove the useless text, which is not a part of the description for rooms or sensors, or not appear in the benchmark result set. 5 The <a href="javascript:openDSC(3588250180, 3722, '23172');" onmouseover="doRollover(7);" onmouseout="undoRollover(7);" id="23172" name="7" ><span class="b-ref">7</span>term CRLF refers to Carriage Return (ASCII 13, \r) Line Feed (ASCII 10, \n). They’re used to note the termination of a line, however, dealt with differently in today’s popular Operating Systems.</a><a href="javascript:openDSC(308090156, 3791, '25558');" onmouseover="doRollover(20);" onmouseout="undoRollover(20);" id="25558" name="20" ><span class="b-ref">20</span>Chapter 6<span> Achievements </span>and<span> Conclusions </span>In this chapter, the<span> findings, </span>goals</a> achievements and some further works will be introduced. Meanwhile, a conclusion will be made to summarize the whole task. 6.1 Findings and Goals Achievements These tasks involved two different languages, therefore it will be a problem when eventually integrate all process. To solve this problem, shell scripts are used to connect the different part of the pipeline when they are assembled. Table 6.1 shows the goals achievements, where all functions have been implemented by Java or Python, no matter the necessity is Mandatory or Optional. Also, an improved function, which is used to split rooms and obtain its range, named OpenCV Room Divider has been implemented. However, it works terrible for the building drawings. 6.2 Further work Mainly, increase the performance of the relationship extraction pipeline should be a vital work in the future. One is to integrate the OpenCV Room Divider into the final pipeline. Other is to try various clustering method to improve accuracy. 6.2.1 Improvement in OpenCV Room Divider Even though the room range divider has already been implemented, it still works not ideally for the building drawings. After observation, the main reason is the drawings themselves, where the lines of rooms are not apparent sufficiently so that the divider is not sensitive enough to obtain all range of rooms. What is more, there are many irrelevant lines representing facilities and it will interfere with the rooms segmentation. 51 CHAPTER 6. ACHIEVEMENTS AND CONCLUSIONS 52 <a href="javascript:openDSC(630550565, 2, '225');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="225" name="1" ><span class="b-ref">1</span>Function Sub-function ID Necessity<span> Completeness </span>Text and PDFBox Extractor 1.1 Mandatory</a> Fully Achieved coordinate Extraction PDFMiner Extractor 1.2 Optional Fully Achieved OpenCV Extractor 1.3 Optional Fully Achieved <a href="javascript:openDSC(630550565, 2, '249');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="249" name="1" ><span class="b-ref">1</span>Euclidean Distance 2.1 Mandatory<span> Fully Achieved </span>Relationship<span> Extraction </span>K-Means Clustering 2.2 Optional</a> Fully Achieved OpenCV Room Divider 2.3 Improvement Partially Achieved Purity metric 3.1 Mandatory Fully Achieved Evaluation Rand Index metric 3.2 Optional Fully Achieved F-measure metric 3.3 Optional Fully Achieved Table 6.1: The Function Achievements 6.2.2 Improvement in Relationship Extraction There is a series type of clustering methods except for the K-means clustering such as DBSCAN 6, which is a density-based method or GMM 7, which is a model-based method. Furthermore, neural networks can be taken into consideration. For example, SOM 8 is an unsupervised learning model, which often used in clustering. 6.3 Conclusions My initial ambition is to build a system, which can automatically extract information form building drawings and monitor all rooms. Owing to the enormous difficulty, it quite complicated to implement the whole system. Therefore, I focus on the extraction process, especially in the extraction of the relationship between rooms and sensors. To solve this problem, a relationship extraction pipeline is carried out. More specifically, the pipeline is divided into there sub-tasks. For the first sub-task, all texts and coordinates need to be drawn from PDF file. In order to tackle this sub-task, three extractors, which named PDFMiner Extractor, PDFBox Extractor and OpenCV Extractor <a href="javascript:openDSC(643596921, 37, '22758');" onmouseover="doRollover(12);" onmouseout="undoRollover(12);" id="22758" name="12" ><span class="b-ref">12</span>6 Density-Based Spatial Clustering of Applications with Noise 7</a> Gaussian Mixture Models 8 Self Organized Maps respectively, are introduced. At last, the PDFBox Extractor is determined as a part of CHAPTER 6. ACHIEVEMENTS AND CONCLUSIONS 53 the relationship extraction pipeline because it is more accurate than others in terms of performance. The next sub-task is to extract the relationship between all texts, which are extracted by the previous sub-task. Hence, the performance of this sub-task depends on its performance and the previous results. To figure out this sub-task, two clustering methods, which are Euclidean Distance <a href="javascript:openDSC(54883362, 37, '4451');" onmouseover="doRollover(25);" onmouseout="undoRollover(25);" id="4451" name="25" ><span class="b-ref">25</span>Clustering and K-Means<span> Clustering, </span>are in<span> use. Eventually, </span>the</a> Euclidean Distance Clustering is treated as a part of the final relationship extraction pipeline because K-Means Clustering cannot divide all rooms into different groups. Meanwhile, to make the result more accurate, an auxiliary tool named OpenCV Room Divider, which is used to extract the range of rooms, is implemented at the same time. However, it has been emphasised that it is not suitable for the building drawing PDF file, thereby it is not the main part of the relationship extraction pipeline but only plays a supporting role. The last sub-task is an evaluation task, where it contains three different assessments. Purity, Rand Index and F-measure metrics are all implemented to evaluate the performance of the extraction pipeline. After testing, the pipeline can provide a certain amount of extraction capacity. <a href="javascript:openDSC(630550565, 2, '269');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="269" name="1" ><span class="b-ref">1</span>To conclude, a series of experiments show that it is possible to extract the relationship between rooms and sensors from the building drawings with the extraction pipeline up to now. Besides, when the pipeline is assembled finally, it might be a risk in applying different program language, which is caused by<span> various </span>tools. In the next step of this work, we will try to focus on increasing the performance of this pipeline,</a> significantly improving the capacity of OpenCV room divider <a href="javascript:openDSC(630550565, 2, '276');" onmouseover="doRollover(1);" onmouseout="undoRollover(1);" id="276" name="1" ><span class="b-ref">1</span>to do the boundaries detection, so that the error rate could be reduced. Bibliography Fujino, A., Isozaki, H., and Suzuki, J. (2008). Multi-label text categorization with model combination based on f1-score maximization. In Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-II. Huang, Z. (1998). Extensions to the k-means algorithm for clustering large data sets with categorical values. Data Mining and Knowledge Discovery, 2(3):283–304. Jia, R., Jin, B., Jin, M., Zhou, Y., Konstantakopoulos, I. C., Zou, H., Kim, J., Li, D., Gu, W., Arghandeh, R., Nuzzo, P., Schiavon, S., Sangiovanni-Vincentelli, A. L., and Spanos, C. J. (2018). Design automation for smart building systems. Proceedings of the IEEE, 106(9):1680–1699. Kay, A. (2007). Tesseract: an open-source optical character recognition engine. Linux Journal, 2007(159):2. Lee, H., Malaspina, D., Ahn, H., Perrin, M., Opler, M. G., Kleinhaus, K., Harlap, S., Goetz, R., and Antonius, D. (2011). Paternal age related schizophrenia (pars): Latent subgroups detected by k-means clustering analysis. Schizophrenia Research, 128(1-3):143–149. MacQueen, J. et al. (1967). Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, volume 1, pages 281–297. Oakland, CA, USA. Na, S., Xumin, L., and Yong, G. (2010). Research on k-means clustering algorithm: An improved k-means clustering algorithm. In 2010 Third International Symposium on Intelligent Information Technology and Security Informatics, pages 63–67. IEEE. Nimlyat, P. S. (2018). Indoor environmental quality performance and occupants’ satisfaction [ieqpos] as assessment criteria for green healthcare building rating. Building and Environment, 144:598–610. Omarov, B., Altayeva, A., and Cho, Y. I. (2017). Smart building climate control considering indoor and outdoor parameters. In Saeed, K., Homenda, W., and Chaki, R., editors, Computer Information Systems and Industrial Management, pages 412–422, Cham. Springer International Publishing.<span> 54 </span>BIBLIOGRAPHY<span> 55 PDFBoxr, </span>A. (2010). Apache<span> pdfboxr - </span>a java pdf library. The Apache Software Foundation. Pulli, K., Baksheev, A., Kornyakov, K., and Eruhimov, V. (2012). Realtime computer vision with opencv. Queue, 10(4):40–56. Rand, W. M. (1971a). Objective criteria for the evaluation of clustering methods. Journal of the American Statistical Association, 66(336):846–850. Rand, W. M. (1971b). Objective criteria for the evaluation of clustering methods. Journal of the American Statistical association, 66(336):846–850. Rice, S. V., Jenkins, F. R., and Nartker, T. A. (1995). The fourth annual test of ocr accuracy. Technical report, Technical Report 95. Sanderson, M. (2010). Christopher d. manning, prabhakar raghavan, hinrich<span> schu¨tze, </span>introduction to information retrieval, cambridge university press 2008. isbn-13 978-0-521- 86571-5, xxi + 482 pages. Nat. Lang. Eng., 16(1):100–103. Shinyama, Y. (2015). Pdfminer: Python pdf parser and analyzer (2010). Cited on, 13. Sripada, S. C. and Rao, M. S. (2011). Comparison of purity and entropy of k-means clustering and fuzzy c means clustering. Indian journal of computer science and engineering, 2(3):343–346. Tadokoro, S., Jia, Q.-S., Zhao, Q., Darabi, H., Huang, G., Becerik-Gerber, B., Sandberg, H., and Johansson, K. H. (2014). Smart building technology [tc spotlight]. IEEE Robotics &amp; Automation Magazine, 21(2):18–20. Vincent, L. and Lead, U. T. (2007). Announcing tesseract ocr. Google Code Blog, August 2006, 31. Wagstaff, K., Cardie, C., Rogers, S.,<span> Schr¨odl, S., </span>et al. (2001). Constrained k-means clustering with background knowledge. In Icml, volume 1, pages 577–584. Young, G. and Householder, A. S. (1938). Discussion of a set of points in terms of their mutual distances. Psychometrika, 3:19 – 22. Zhou, X., Yao, C., Wen, H., Wang, Y., Zhou, S., He, W., and Liang, J. (2017). East: an efficient and accurate scene text detector. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 5551–5560.<span> Appendices 56 </span>Appendix A An<span> Appendix </span>of<span> Project </span>Gantt Chart<span> 57 </span>APPENDIX A. AN APPENDIX OF PROJECT GANTT CHART<span> 58 </span>APPENDIX A. AN APPENDIX OF PROJECT GANTT CHART<span> 59 </span>CHAPTER 2. LITERATURE SURVEY<span> 5 </span>CHAPTER 2. LITERATURE SURVEY<span> 6 </span>CHAPTER 2. LITERATURE SURVEY<span> 7 </span>CHAPTER 2. LITERATURE SURVEY<span> 8 </span>CHAPTER 2. LITERATURE SURVEY<span> 9 </span>CHAPTER 2. LITERATURE SURVEY<span> 10 </span>CHAPTER 2. LITERATURE SURVEY<span> 11 </span>CHAPTER 2. LITERATURE SURVEY<span> 12 </span>CHAPTER 2. LITERATURE SURVEY<span> 13 </span>CHAPTER</a><a href="javascript:openDSC(626228305, 2, '461');" onmouseover="doRollover(3);" onmouseout="undoRollover(3);" id="461" name="3" ><span class="b-ref">3</span>5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>22 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>23 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>24 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>25 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>26 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>27 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>28 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>29 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>30 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>31 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>32 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>33 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>34 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>35 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>36 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>37 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>38</a><a href="javascript:openDSC(606350286, 2, '14434');" onmouseover="doRollover(2);" onmouseout="undoRollover(2);" id="14434" name="2" ><span class="b-ref">2</span>CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>39 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>40 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>41 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>42 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>43 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>44 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>45 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>46 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>47 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>48 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>49 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>50 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>51 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>52 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>53 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>54 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>55 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>56 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>57 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>58 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>59 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>60 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>61 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>62 CHAPTER 5. IMPLEMENTATION,<span> ASSEMBLY, TEST </span>AND<span> EVALUATION </span>63</a> CHAPTER 5. IMPLEMENTATION, ASSEMBLY, TEST AND EVALUATION 64 
</div>
</div>
</body>
</html>
